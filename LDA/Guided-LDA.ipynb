{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import guidedlda\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 how to access google\n",
       "1                      how to access missed call alert\n",
       "2          how to access my sd card on myideafi device\n",
       "3    how to access myidea fi device for changing pa...\n",
       "4    how to access that one video is taking how muc...\n",
       "Name: Utterances, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('dataNLU.xlsx')\n",
    "data = df['Utterances']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidedlda.datasets.load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/krishna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'extend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-30dd41f7422b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                ]\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'set' object has no attribute 'extend'"
     ]
    }
   ],
   "source": [
    "# Adding some domain specific stopwords\n",
    "domain_words = [\"access\", \"account\", \"activate\", \"remedy\", \"add on\",\n",
    "               \"usage alert\", \"celebration\", \"data booster\", \"idea data booster\", \n",
    "                \"idea data plan\", \"idea plan\", \"data plan\", \"idea tune subscription\",\n",
    "               \"idea tune\", \"slow internet\", \"internet\", \"idea subscription\", \n",
    "               \"message\", \"ideaphone\", \"ideanet\", \"ideatv\", \"idea phone\",\n",
    "               \"idea net\", \"idea tv\", \"idea sim\", \"ideasim\", \"boost\", \"idea data\", \n",
    "               \"myidea\", \"postpaid\", \"special pack\", \"voucher\", \"password\", \"call\",\n",
    "               \"account\", \"application\", \"delete\", \"download\", \"aadhar\", \n",
    "               \"idea app\", \"recharge\", \"photos\", \"messages\", \"msg\", \"sms\",\n",
    "               \"idea\", \"caller tune\", \"customer\", \"hello tune\", \"idea\",\n",
    "               \"idea tune\", \"alert\", \"missed call\", \"ideamusic\", \"idea music\",\n",
    "               \"hotspot\", \"network\", \"stop\", \"take\", \"unblock\", \"how to use\", \n",
    "               ]\n",
    "stopwords.extend(domain_words)\n",
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = CountVectorizer(ngram_range=(1,4), min_df=1, max_df=.80, stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Y.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4565, 10227)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Y.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_names = Y.get_feature_names()\n",
    "word2id = dict((v, idx) for idx, v in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topic_list = [\n",
    "    [\"data booster\", \"data pack\"],\n",
    "    [\"dairy milk\", \"myideaapp\", \"offer\"],\n",
    "    [\"ideatune\", \"subscription\", \"recharges\"],\n",
    "    [\"sim card\", \"contact number\", \"number\"],\n",
    "    [\"phone\", \"booking\"],\n",
    "    [\"change\", \"accounts\", \"number\"],\n",
    "    [\"check\", \"data\", \"information\"],\n",
    "    [\"myideaapp\", \"connect\", \"myideafi device\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = guidedlda.GuidedLDA(n_topics = 15, n_iter = 500, random_state = 4 ,refresh = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topics = {}\n",
    "for t_id, st in enumerate(seed_topic_list):\n",
    "    for word in st:\n",
    "        seed_topics[word2id[word]] = t_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:guidedlda:n_documents: 4565\n",
      "INFO:guidedlda:vocab_size: 10227\n",
      "INFO:guidedlda:n_words: 22675\n",
      "INFO:guidedlda:n_topics: 15\n",
      "INFO:guidedlda:n_iter: 500\n",
      "WARNING:guidedlda:all zero row in document-term matrix found\n",
      "INFO:guidedlda:<0> log likelihood: -330363\n",
      "INFO:guidedlda:<20> log likelihood: -208892\n",
      "INFO:guidedlda:<40> log likelihood: -206168\n",
      "INFO:guidedlda:<60> log likelihood: -204165\n",
      "INFO:guidedlda:<80> log likelihood: -203104\n",
      "INFO:guidedlda:<100> log likelihood: -202328\n",
      "INFO:guidedlda:<120> log likelihood: -202150\n",
      "INFO:guidedlda:<140> log likelihood: -201612\n",
      "INFO:guidedlda:<160> log likelihood: -201137\n",
      "INFO:guidedlda:<180> log likelihood: -201014\n",
      "INFO:guidedlda:<200> log likelihood: -200730\n",
      "INFO:guidedlda:<220> log likelihood: -200543\n",
      "INFO:guidedlda:<240> log likelihood: -200307\n",
      "INFO:guidedlda:<260> log likelihood: -200206\n",
      "INFO:guidedlda:<280> log likelihood: -200165\n",
      "INFO:guidedlda:<300> log likelihood: -199979\n",
      "INFO:guidedlda:<320> log likelihood: -200023\n",
      "INFO:guidedlda:<340> log likelihood: -199981\n",
      "INFO:guidedlda:<360> log likelihood: -199935\n",
      "INFO:guidedlda:<380> log likelihood: -199971\n",
      "INFO:guidedlda:<400> log likelihood: -199766\n",
      "INFO:guidedlda:<420> log likelihood: -199791\n",
      "INFO:guidedlda:<440> log likelihood: -199453\n",
      "INFO:guidedlda:<460> log likelihood: -199200\n",
      "INFO:guidedlda:<480> log likelihood: -199414\n",
      "INFO:guidedlda:<499> log likelihood: -199261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<guidedlda.guidedlda.GuidedLDA at 0x11c5a1208>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, seed_topics=seed_topics, seed_confidence=0.25)\n",
    "# pickle.dump(model, open('model','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "data/add/pack/use\n",
      "1\n",
      "tune/change/set/caller\n",
      "2\n",
      "set/new/phone/ringtone\n",
      "3\n",
      "use/play/coupon/kbc\n",
      "4\n",
      "use/redeem/coupons/get\n",
      "5\n",
      "voice/phone/set/connect\n",
      "6\n",
      "make/change/mobile/device\n",
      "7\n",
      "get/free/offer/pack\n",
      "8\n",
      "use/vouchers/data/get\n",
      "9\n",
      "number/mobile/change/sim\n",
      "10\n",
      "data/know/check/balance\n",
      "11\n",
      "milk/dairy/dairy milk/data\n",
      "12\n",
      "data/get/gb/plan\n",
      "13\n",
      "data/speed/increase/check\n",
      "14\n",
      "number/another/ideanumber/vouchers\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 1\n",
    "topic_word = model.topic_word_\n",
    "\n",
    "no_top_words = 4\n",
    "\n",
    "def display_topics(feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(topic_idx)\n",
    "        print(\"/\".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        \n",
    "display_topics(tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guided LDA Model recognises these 15 topics. The topics are similar to the ones recognised by the LDA Model and once again, garbage data and data with low representation are not included in these sentences. Despite seeding some domain words and topics, the results are no better than provided by LDA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
