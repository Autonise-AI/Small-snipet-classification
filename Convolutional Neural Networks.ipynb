{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading the dataset generated using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = 0.9\n",
    "\n",
    "with open('final_data_google.p', 'rb') as f:\n",
    "\tdata_ = pickle.load(f)\n",
    "\tidx = np.arange(data_[0].shape[0])\n",
    "\tnp.random.shuffle(idx)\n",
    "\n",
    "\ttrain_data = data_[0][idx[:int(idx.shape[0]*split)]]\n",
    "\ttrain_truth = data_[1][idx[:int(idx.shape[0]*split)]]\n",
    "\t\n",
    "\ttest_data = data_[0][idx[int(idx.shape[0]*split):]]\n",
    "\ttest_truth = data_[1][idx[int(idx.shape[0]*split):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train dataloader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class train_DataSet(data.Dataset):\n",
    "\n",
    "\tdef __init__(self, train_data, train_truth):\n",
    "\n",
    "\t\tself.train_data = train_data\n",
    "\t\tself.truth = train_truth\n",
    "\n",
    "\t\treturn\n",
    "\n",
    "\tdef __getitem__(self,index):\n",
    "\n",
    "\t\treturn (self.train_data[index][None,:,:], np.argmax(self.truth[index]))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\n",
    "\t\treturn len(self.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test dataloader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class test_DataSet(data.Dataset):\n",
    "\n",
    "\tdef __init__(self, test_data, test_truth):\n",
    "\n",
    "\t\tself.train_data = test_data\n",
    "\t\tself.truth = test_truth\n",
    "\n",
    "\tdef __getitem__(self,index):\n",
    "\n",
    "\t\treturn (self.train_data[index][None,:,:], np.argmax(self.truth[index]))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\n",
    "\t\treturn len(self.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Network architecture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, first, second):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(300, first, kernel_size=(3,1), padding=(1, 0))\n",
    "        self.conv2 = nn.Conv2d(first, second, kernel_size=(3,1), padding=(1, 0))\n",
    "        self.conv3 = nn.Conv2d(second, 444, kernel_size=(1,1), padding=(0, 0))\n",
    "        self.final = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.final(x).squeeze().unsqueeze(0)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialising To save variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_max_accuracy = np.zeros([len(range(20, 100, 20)), len(range(50, 150, 20))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model architecture varied on grid\n",
    "#Training and Testing and reporting the results\n",
    "#Batch size = 10\n",
    "#Learning Rate fixed to 0.001 (Adaptive Learning rate of Adam Optimizer assures convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ____i, first in enumerate(range(20, 100, 20)):\n",
    "\tfor ____j, second in enumerate(range(50, 150, 20)):\n",
    "        net = Net(first , second).cuda()\n",
    "\t\ttrainloader = train_DataSet(train_data, train_truth)\n",
    "\t\ttestloader = test_DataSet(test_data, test_truth)\n",
    "\t\tprint(net)\n",
    "        batch_size = 10\n",
    "\t\tcriterion = nn.CrossEntropyLoss()\n",
    "\t\toptimizer = optim.Adam(net.parameters(), lr=0.01/batch_size)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tsteps = 0\n",
    "\t\tfor epoch in range(30):\n",
    "\n",
    "\t\t\trunning_loss = 0.0\n",
    "\t\t\tcorrect = 0\n",
    "\n",
    "\t\t\tnet.train()\n",
    "\t\t\t\n",
    "\t\t\tfor i, data in enumerate(trainloader):\n",
    "\t\t\t\t# get the inputs\n",
    "\t\t\t\tinputs, labels = data\n",
    "\t\t\t\tinputs = inputs[None, :, :, :].transpose(0, 3, 2, 1)\n",
    "\t\t\t\tlabels = np.array([labels])\n",
    "\n",
    "\t\t\t\tinputs = Variable(torch.from_numpy(inputs).cuda())\n",
    "\t\t\t\tlabels = Variable(torch.from_numpy(labels).cuda())\n",
    "\n",
    "\t\t\t\toutputs = net(inputs)\n",
    "\t\t\t\tv, index = torch.max(outputs,1)\n",
    "\t\t\t\tindex = index[0].data.cpu().numpy()\n",
    "\n",
    "\t\t\t\tif index == labels.data.cpu().numpy()[0]:\n",
    "\t\t\t\t\tcorrect += 1\n",
    "\n",
    "\t\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\t\tloss.backward()\n",
    "\n",
    "\t\t\t\tif i % batch_size == 0 and i!=0:\n",
    "\t\t\t\t\toptimizer.step()\n",
    "\t\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\t\tsteps += 1\n",
    "\n",
    "\t\t\t\trunning_loss += loss.item()\n",
    "\n",
    "\t\t\tprint('\\n\\n--------------------------------------')\n",
    "\n",
    "\t\t\tprint('Epoch: ', epoch + 1)\n",
    "\t\t\tprint('Steps: ', steps)\n",
    "\t\t\tprint('Train accuracy: ', correct/len(trainloader))\n",
    "\t\t\tprint('Train loss: ', running_loss / len(trainloader))\n",
    "\t\t\t\n",
    "\t\t\trunning_loss = 0.0\n",
    "\t\t\tcorrect = 0\n",
    "\n",
    "\t\t\tnet.eval()\n",
    "\n",
    "\t\t\tfor i, data in enumerate(testloader):\n",
    "\n",
    "\t\t\t\tinputs, labels = data\n",
    "\t\t\t\tinputs = inputs[None, :, :, :].transpose(0, 3, 2, 1)\n",
    "\t\t\t\tlabels = np.array([labels])\n",
    "\n",
    "\t\t\t\tinputs = Variable(torch.from_numpy(inputs).cuda())\n",
    "\t\t\t\tlabels = Variable(torch.from_numpy(labels).cuda())\n",
    "\n",
    "\t\t\t\toutputs = net(inputs)\n",
    "\t\t\t\tv, index = torch.max(outputs,1)\n",
    "\t\t\t\tindex = index[0].data.cpu().numpy()\n",
    "\n",
    "\t\t\t\tif index == labels.data.cpu().numpy()[0]:\n",
    "\t\t\t\t\tcorrect += 1\n",
    "\n",
    "\t\t\t\tloss = criterion(outputs, labels)\n",
    "\n",
    "\t\t\t\tif i % batch_size == 0 and i!=0:\n",
    "\t\t\t\t\toptimizer.step()\n",
    "\t\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\t\tsteps += 1\n",
    "\t\t\t\t\t\n",
    "\t\t\t\trunning_loss += loss.item()\n",
    "\n",
    "\t\t\tprint('Test accuracy = ', correct/len(testloader))\n",
    "\t\t\tprint('Test loss = ', running_loss/len(testloader))\n",
    "\n",
    "\t\t\tif correct/len(testloader) > all_max_accuracy[____i, ____j]:\n",
    "\t\t\t\tall_max_accuracy[____i, ____j] = correct/len(testloader)\n",
    "\n",
    "print(all_max_accuracy)\n",
    "np.save('Grid Run results', all_max_accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
